# -*- coding: utf-8 -*-
"""ADS Exp 1 & 9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pIYPPlnC44I4GLsK8jvqMvWrynm0OKpg

**DESCRIPTIVE STATISTICS**
"""

import pandas as pd
import numpy as np

rainfall_df = pd.read_csv('ADS_dataset.csv')
rainfall_df.head()

rainfall_df.describe()

rainfall_df.mode().head()

from tabulate import tabulate

rf_df = rainfall_df.drop(['Date'],axis=1)
cols=["Column"]
modes=["Mode"]
for (columnName, columnData) in rf_df.iteritems():
  # lst = []
  x = rf_df[columnName].mode()
  cols.append(columnName)
  modes.append(x[0])

print(tabulate([cols,modes],tablefmt="grid"))

rf_df = rainfall_df.drop(['Date','Location','WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow'],axis=1)
print('-----------SUM-------------')
rf_df.sum().head()

print('---------RANGE---------')
print(rf_df.max() - rf_df.min())

des = rainfall_df.describe()
print('---------IQR----------')
print(des.loc['75%'] - des.loc['25%'])

print('---------VARIANCE----------')
rf_df.var()

print('CORRELATION:')
rf_df.corr()

print('-------SE of Mean---------')
rf_df.sem()

print('--Coefficient of Variation--')
cv = lambda x: np.std(x) / np.mean(x) * 100
rf_df.apply(cv)

print('-No. of missing values-')
rainfall_df.isnull().sum()

print('---Total no. of values---')
rainfall_df.count()

print("Cummulative Frequency:")
rf_df.cumsum(axis=0).head()

print('Percentage:')
per_df = pd.DataFrame()
for (columnName, columnData) in rf_df.iteritems():
  per_df[columnName] = (rf_df[columnName] / rf_df[columnName].sum()) * 100

per_df.head()

print('Cummulative Percentage:')
cum_per_df = pd.DataFrame()
for (columnName, columnData) in rf_df.iteritems():
  cum_per_df[columnName] = (rf_df[columnName].cumsum() / rf_df[columnName].sum()) * 100

cum_per_df.head()

from scipy import stats

print('5% Trimmed Mean')
tr_mean=["Trimmed Mean"]
for (columnName, columnData) in rf_df.iteritems():
  x = stats.trim_mean(rf_df[columnName], 0.05) 
  tr_mean.append(round(x,2))

print(tabulate([cols,tr_mean],tablefmt="grid"))

print('Sum of Squares:')
sos=["Sum of Squares"]
for (columnName, columnData) in rf_df.iteritems():
  x =  rf_df[columnName].pow(2).sum()
  sos.append(round(x,2))

print(tabulate([cols,sos],tablefmt="grid"))

print('---------Skewness--------')
rf_df.skew()

print('----------Kurtosis----------')
rf_df.kurtosis()

import matplotlib.pyplot as plt

box_df = rf_df[['MinTemp','MaxTemp','Rainfall']]
fig = plt.figure(figsize =(10, 7))
plt.boxplot(box_df.head(50))
plt.show()

x = rf_df['MinTemp']
y = rf_df['Rainfall']

fig = plt.figure(figsize =(10, 7))
plt.scatter(x,y)
plt.show()

import seaborn as sns

corr = rf_df.corr()
plt.figure(figsize=(15,15),dpi=600)
g=sns.heatmap(corr, square=True,
            center=0, annot=True, linewidths=.5,
            cmap="RdBu_r", cbar_kws={"shrink": 0.8},vmin=-1,vmax=1);
g.set_xticklabels(g.get_xticklabels(),rotation=45,fontsize=8,ha='right')
plt.title('Correlation Matrix')

"""**INFERENTIAL STATISTICS**"""

#NORMAL DISTRIBUTION
import matplotlib.pyplot as plt
import scipy.stats as stats

df_mean = np.mean(rf_df["MinTemp"])
df_std = np.std(rf_df["MinTemp"])

pdf = stats.norm.pdf(rf_df["MinTemp"].sort_values(), df_mean, df_std)

plt.plot(rf_df["MinTemp"].sort_values(), pdf)
plt.xlabel("MinTemp", size=13)    
plt.ylabel("Frequency", size=13)                
plt.show()

#POISSON DISTRIBUTION
from scipy.stats import poisson

k = rf_df['MinTemp'].dropna()
k = k.to_numpy()
avg = rf_df['MinTemp'].mean()
pmf = poisson.pmf(k, mu=avg)

plt.plot(k, pmf,marker='o')
plt.xlabel('MinTemp',size=13)
plt.ylabel('Probability',size=13)
plt.show()

#CONFIDENCE INTERVAL & SAMPLING ERROR
from scipy.stats import t

x = rf_df['Rainfall']
m = x.mean() 
print("Mean =",m)

s = x.std() 
dof = len(x)-1 
confidence = 0.95

t_crit = np.abs(t.ppf((1-confidence)/2,dof))
print("Sampling Error =",s*t_crit/np.sqrt(len(x)))
print("With 95% confidence, the expected value of the population lies between {:.2f} and {:.2f}".format(m-s*t_crit/np.sqrt(len(x)), m+s*t_crit/np.sqrt(len(x))))

#Z-TEST
from bioinfokit.analys import stat
print('Null Hypothesis: mu equal to mu0')
pop_mean = rf_df['Rainfall'].mean()
print('Population Mean =',pop_mean)
pop_std = rf_df['Rainfall'].std()

sample = rf_df[['Rainfall']].sample(n=29)

res = stat()
res.ztest(df=sample,x='Rainfall',mu = pop_mean, x_std = pop_std, alpha=0.05,test_type=1)
print(res.summary)

z, p = res.result[1], res.result[3]
if(p<0.05):
  print("Reject Null Hypothesis")
else:
  print("Accept Null Hypothesis")

#T-TEST & TYPE I & TYPE II ERROR
import scipy.stats as stats

print('Null Hypothesis: mu1 equal to mu2')
data_group1 = rf_df['MinTemp'].sample(10).dropna()
data_group1 = data_group1.to_numpy() 
data_group2 = rf_df['MaxTemp'].sample(10).dropna()
data_group2 = data_group2.to_numpy()
res = stats.ttest_ind(a=data_group1, b=data_group2,equal_var=True)

print(res)

p = res[1]
if(p < 0.05):
  print("Reject Null Hypothesis. Type I error.")
else:
  print("Accept Null Hypothesis. Type II error.")

#ANOVA TEST
import scipy.stats as stats

d1 = rf_df['WindGustSpeed'].dropna()
d2 = rf_df['WindSpeed9am'].dropna()
d3 = rf_df['WindSpeed3pm'].dropna()
fvalue, pvalue = stats.f_oneway(d1.head(5),d2.head(5),d3.head(5))

print("H0: μ1 = μ2 = μ3")
print("H1: The means are not equal")
print("F value = {:.4f} and P value = {:.4f}".format(fvalue, pvalue))

if(pvalue < 0.05):
  print("Reject Null Hypothesis")
else:
  print("Accept Null Hypothesis")