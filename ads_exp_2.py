# -*- coding: utf-8 -*-
"""ADS Exp 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13qQTPdtpJYfgpAcjbpczytDomeE_mu8I
"""

import pandas as pd

rf_df = pd.read_csv('ADS_dataset.csv')
rf_df.head()

#Deletion of row with missing data

df1 = rf_df.dropna();
df1.head()

#Mean Imputation

df2 = rf_df.fillna(rf_df.mean())
df2.head()

#Median Imputation

df3 = rf_df.fillna(rf_df.median())
df3.head()

#Mode Imputation / Frequent Category Imputation

df4=rf_df.fillna(rf_df.mode().iloc[0])
df4.head()

#Arbitary value Imputation

df5 = rf_df.copy()
df5 = df5.fillna({'MinTemp':13.1,'MaxTemp':30.1,'Rainfall':1.4,'Evaporation':7.8,'Sunshine': 2.7,'WindGustDir':'W','WindGustSpeed':44,'WindDir9am':'W','WindDir3pm':'WNW','WindSpeed9am':20,
                  'WindSpeed3pm':24,'Humidity9am':71,'Humidity3pm':22,'Pressure9am':1007.7,'Pressure3pm':1007.1,'Cloud9am':8,'Cloud3pm':2,'Temp9am':16.9,'Temp3pm':21.8,'RainToday':'No',
                  'RainTomorrow':'No'})
df5.head()

#End of Tail Imputation

df6 = rf_df.copy()
extreme=df6.mean()+3*df6.std()
df7=df6.fillna(extreme)
df7.head()

#Adding a new category as "missing"

df9 = rf_df.copy()
df9.fillna("missing", inplace=True)
df9.head()

#Random Sample Imputation

df8 = rf_df.copy()

for column in df8.columns:
    missing_values = df8[column].isna().sum()
    if missing_values:
        values = df8[column].dropna().sample(missing_values, replace=True)
        df8[column][df8[column].isna()] = values.values

df8.head()

#Regression Imputation

df10 = rf_df.copy()

corr = df10.corr()
corr.style.background_gradient(cmap='coolwarm').set_precision(2)

df10['Temp3pm'].fillna(round(df10['Temp3pm'].mean(),1),inplace=True)

df10['Temp3pm'].isnull().sum()

df_temp3pm = df10.dropna(axis=0, subset=['MaxTemp', 'Temp3pm'])
df_temp3pm = df_temp3pm.loc[:, ['MaxTemp', 'Temp3pm']]

missing_maxtemp = df10['MaxTemp'].isnull();
df11 = pd.DataFrame(df10['Temp3pm'][missing_maxtemp])
df11.head()

df_temp3pm.head()

df_temp3pm.isnull().any()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

X = df_temp3pm[['Temp3pm']]
Y = df_temp3pm['MaxTemp']

X_train, X_test, y_train, y_test =  train_test_split(X, Y, test_size=0.2, random_state=101)
lm = LinearRegression().fit(X_train, y_train)
pred = lm.predict(df11)

pred_df = pd.DataFrame(pred)
pred_df.head()

c=0
for ind in df11.index:
  df10['MaxTemp'][ind] = round(pred_df[0][c],1)
  c+=1

print(df10['MaxTemp'][283])

import matplotlib.pyplot as plt

# Bar chart

loc_temp = {}

loc = df2['Location']
temp = df2['MaxTemp']

for i in range(145460):
  loc_temp[loc[i]] = [0, 0]

for i in range(145460):
  loc_temp[loc[i]][0] += temp[i]
  loc_temp[loc[i]][1] += 1

loc_array = []
avg_temp_array = []

for loc in loc_temp:
  loc_array.append(loc) 
  avg_temp_array.append(loc_temp[loc][0] /  loc_temp[loc][1])

fig = plt.figure(figsize = (60, 15))

plt.bar(loc_array, avg_temp_array, color ='maroon', width = 0.4)
plt.rcParams.update({'font.size': 10})
plt.xlabel("Location", fontsize=50)
plt.ylabel("Avg MaxTemp", fontsize=50)
plt.title("Bar chart", fontsize=50)
plt.show()

import seaborn as sns

# Heatmap

corr = rf_df.corr()
plt.figure(figsize=(8,8),dpi=300)
g=sns.heatmap(corr, square=True,
            center=0, annot=True, linewidths=.5,
            cmap="RdBu_r", cbar_kws={"shrink": 0.8},vmin=-1,vmax=1, annot_kws={'size': 5});
g.set_xticklabels(g.get_xticklabels(),rotation=45,fontsize=5,ha='right')
g.set_yticklabels(g.get_yticklabels(),fontsize=5,ha='right')
plt.title('Heatmap', fontsize=5)