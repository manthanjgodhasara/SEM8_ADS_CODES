# -*- coding: utf-8 -*-
"""ADS Exp 6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10xJqJRUWi-4ZiwmZsZpQWs6CJp032Cdi
"""

from statsmodels.tsa.seasonal import seasonal_decompose
from dateutil.parser import parse
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('ADS_dataset.csv')
df.head()

#preprocessing
df = df.fillna(df.mean())
df.head()

df['Date'] = pd.to_datetime(df['Date'])

# set Date column as index
df.set_index('Date', inplace=True)
df.head()

plt.rcParams.update({'figure.figsize': (10,6)})
plt.plot(df['MinTemp'])

df['Rainfall'].fillna(df['Rainfall'].mean(),inplace=True)

# Additive Decomposition
add_result = seasonal_decompose(df['Rainfall'], model='additive',period=1)

add_result.plot()
plt.show()

new_df_add = pd.concat([add_result.seasonal, add_result.trend, add_result.resid, add_result.observed], axis=1)
new_df_add.columns = ['seasoanilty', 'trend', 'residual', 'actual_values']
new_df_add.head()

df.drop(['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainTomorrow'], axis='columns', inplace=True)
df['RainToday'] = df['RainToday'].fillna('No')

#encoding
df.RainToday = df.RainToday.map({'Yes': 1, 'No': 0})
df.head()

from statsmodels.graphics.tsaplots import plot_acf,plot_pacf

# plot the ACF
fig, ax = plt.subplots(figsize=(12, 5))
plot_acf(df['MinTemp'], lags=50, ax=ax)
plt.show()

# plot the PACF
fig, ax = plt.subplots(figsize=(12, 5))
plot_pacf(df['MinTemp'], lags=50, ax=ax)
plt.show()

#Augmented Dickey- Fuller test(ADF)
from statsmodels.tsa.stattools import adfuller
adfuller_result = adfuller(df['MinTemp'], autolag='AIC')
print(f'ADF Statistic: {adfuller_result[0]}')
print(f'p-value: {adfuller_result[1]}')
for key, value in adfuller_result[4].items():
    print('Critial Values:')
    print(f'   {key}, {value}')

#Linear Regression
x = df['MinTemp']
y = df['Rainfall']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7 , random_state=10)

x_train = x_train.values
x_train = x_train.reshape(-1, 1)

x_test = x_test.values
x_test = x_test.reshape(-1, 1)

from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(x_train,y_train)

# Make predictions
predictions = reg.predict(x_test)

# Print the predictions
print(predictions)

# Apply the rolling() function to compute the moving average
moving_average = df['MinTemp'].rolling(window=3).mean()

# Print the original data and the moving average
print(moving_average)

moving_average.plot(color="red")
plt.show()

# Split the data into training and testing sets
train_size = int(len(df) * 0.8)
train_data, test_data = df[:train_size], df[train_size:]

from statsmodels.tsa.arima.model import ARIMA

# Define the parameters for the ARIMA model
p = 1  # order of the autoregressive part
d = 1  # degree of differencing
q = 1  # order of the moving average part

arima_model = ARIMA(train_data['MinTemp'], order=(p, d, q))

arima_fit = arima_model.fit()

predictions = arima_fit.forecast(steps=len(test_data)).values

plt.plot(train_data.index, train_data['MinTemp'], label='Training Data')
plt.plot(test_data.index, test_data['MinTemp'], label='Test Data')
plt.plot(test_data.index, predictions, label='Predictions')
plt.legend()
plt.show()

"""**Mean Absolute error**"""

from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(test_data['MinTemp'],predictions)
print("MAE:", mae)

"""**Mean Absolute Percentage error**"""

import numpy as np

from sklearn.metrics import mean_absolute_percentage_error
mape = mean_absolute_percentage_error(test_data['MinTemp'],predictions)
print("MAPE:", mape)

"""**Mean squared error**"""

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(test_data['MinTemp'],predictions)
print("MSE:", mse)

"""**Root mean squared error**"""

import math
rmse = math.sqrt(mse)
print("RMSE:", rmse)